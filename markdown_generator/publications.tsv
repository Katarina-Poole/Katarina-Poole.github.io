pub_date	title	venue	excerpt	citation	url_slug	paper_url
09/12/2020	An online headphone screening test based on dichotic pitch	Behaviour Research Methods	"Online experimental platforms can be used as an alternative to, or complement, lab-based research. However, when conducting auditory experiments via online methods, the researcher has limited control over the participants’ listening environment. We offer a new method to probe one aspect of that environment, headphone use. Headphones not only provide better control of sound presentation but can also “shield” the listener from background noise. Here we present a rapid (< 3 min) headphone screening test based on Huggins Pitch (HP), a perceptual phenomenon that can only be detected when stimuli are presented dichotically. We validate this test using a cohort of “Trusted” online participants who completed the test using both headphones and loudspeakers. The same participants were also used to test an existing headphone test (AP test; Woods et al., 2017, Attention Perception Psychophysics). We demonstrate that compared to the AP test, the HP test has a higher selectivity for headphone users, rendering it as a compelling alternative to existing methods. Overall, the new HP test correctly detects 80% of headphone users and has a false-positive rate of 20%. Moreover, we demonstrate that combining the HP test with an additional test–either the AP test or an alternative based on a beat test (BT)–can lower the false-positive rate to ~ 7%. This should be useful in situations where headphone use is particularly critical (e.g., dichotic or spatial manipulations). Code for implementing the new tests is publicly available in JavaScript and through Gorilla (gorilla.sc)."	"Milne, A.E., Bianco, R., Poole, K.C., Zhao, S., Oxenham, A.J., Billig, A.J., Chait, M., 2020. An online headphone screening test based on dichotic pitch. Behav. Res. Methods. https://doi.org/10.3758/s13428-020-01514-0"	headphone-screening	https://doi.org/10.3758/s13428-020-01514-0
28/07/2023	How does the brain extract acoustic patterns? A behavioural and neural study	UCL	"In complex auditory scenes the brain exploits statistical regularities to group sound elements into streams. Previous studies using tones that transition from being randomly drawn to regularly repeating, have highlighted a network of brain regions involved during this process of regularity detection, including auditory cortex (AC) and hippocampus (HPC; Barascud et al., 2016). In this thesis, I seek to understand how the neurons within AC and HPC detect and maintain a representation of deterministic acoustic regularity.
I trained ferrets (n = 6) on a GO/NO-GO task to detect the transition from a random sequence of tones to a repeating pattern of tones, with increasing pattern lengths (3, 5 and 7). All animals performed significantly above chance, with longer reaction times and declining performance as the pattern length increased. During performance of the behavioural task, or passive listening, I recorded from primary and secondary fields of AC with multi-electrode arrays (behaving: n = 3), or AC and HPC using Neuropixels probes (behaving: n = 1; passive: n = 1).
In the local field potential, I identified no differences in the evoked response between presentations of random or regular sequences. Instead, I observed significant increases in oscillatory power at the rate of the repeating pattern, and decreases at the tone presentation rate, during regularity. Neurons in AC, across the population, showed higher firing with more repetitions of the pattern and for shorter pattern lengths. Single-units within AC showed higher precision in their firing when responding to their best frequency during regularity. Neurons in AC and HPC both entrained to the pattern rate during presentation of the regular sequence when compared to the random sequence. Lastly, development of an optogenetic approach to inactivate AC in the ferret paves the way for future work to probe the causal involvement of these brain regions.
"	"Poole, K.C., 2023. How does the brain extract acoustic patterns? A behavioural and neural study (Doctoral). Dr. Thesis UCL Univ. Coll. Lond. UCL (University College London)."	phd-thesis	https://discovery.ucl.ac.uk/id/eprint/10173385/
16/11/2021	What can we learn from inactivation studies? Lessons from auditory cortex	Trends in Neuroscience	"Wide variation in the outcome of auditory cortex inactivation has been an impediment to clear conclusions regarding the roles of the auditory cortex in behaviour.
Inactivation methods differ in their efficacy and specificity. The likelihood of observing a behavioural deficit is additionally influenced by factors such as the species being used, task design and reward.
A synthesis of previous results suggests that auditory cortex involvement is critical for tasks that require integrating across multiple stimulus features, and less likely to be critical for simple feature discriminations.
New methods of neural silencing provide opportunities for spatially and temporally precise manipulation of activity, allowing perturbation of individual subfields and specific circuits.
Inactivation experiments in auditory cortex (AC) produce widely varying results that complicate interpretations regarding the precise role of AC in auditory perception and ensuing behaviour. The advent of optogenetic methods in neuroscience offers previously unachievable insight into the mechanisms transforming brain activity into behaviour. With a view to aiding the design and interpretation of future studies in and outside AC, here we discuss the methodological challenges faced in manipulating neural activity. While considering AC’s role in auditory behaviour through the prism of inactivation experiments, we consider the factors that confound the interpretation of the effects of inactivation on behaviour, including the species, the type of inactivation, the behavioural task employed, and the exact location of the inactivation"	"Slonina, Z.A., Poole, K.C., Bizley, J.K., 2022. What can we learn from inactivation studies? Lessons from auditory cortex. Trends Neurosci. 45, 64–77. https://doi.org/10.1016/j.tins.2021.10.00"	opto-review	https://doi.org/10.1016/j.tins.2021.10.005
25/08/2022	The role of temporal coherence and temporal predictability in the build-up of auditory grouping	Scientific Reports	"The cochlea decomposes sounds into separate frequency channels, from which the auditory brain must reconstruct the auditory scene. To do this the auditory system must make decisions about which frequency information should be grouped together, and which should remain distinct. Two key cues for grouping are temporal coherence, resulting from coherent changes in power across frequency, and temporal predictability, resulting from regular or predictable changes over time. To test how these cues contribute to the construction of a sound scene we present listeners with a range of precursor sounds, which act to prime the auditory system by providing information about each sounds structure, followed by a fixed masker in which participants were required to detect the presence of an embedded tone. By manipulating temporal coherence and/or temporal predictability in the precursor we assess how prior sound exposure influences subsequent auditory grouping. In Experiment 1, we measure the contribution of temporal predictability by presenting temporally regular or jittered precursors, and temporal coherence by using either narrow or broadband sounds, demonstrating that both independently contribute to masking/unmasking. In Experiment 2, we measure the relative impact of temporal coherence and temporal predictability and ask whether the influence of each in the precursor signifies an enhancement or interference of unmasking. We observed that interfering precursors produced the largest changes to thresholds."	"Sollini, J., Poole, K.C., Blauth-Muszkowski, D., Bizley, J.K., 2022. The role of temporal coherence and temporal predictability in the build-up of auditory grouping. Sci. Rep. 12, 14493. https://doi.org/10.1038/s41598-022-18583-0"	temporal-coherence	https://doi.org/10.1038/s41598-022-18583-0
01/02/2023	Reversible Inactivation of Ferret Auditory Cortex Impairs Spatial and Nonspatial Hearing	Journal of Neuroscience	"A key question in auditory neuroscience is to what extent are brain regions functionally specialized for processing specific sound features, such as location and identity. In auditory cortex, correlations between neural activity and sounds support both the specialization of distinct cortical subfields, and encoding of multiple sound features within individual cortical areas. However, few studies have tested the contribution of auditory cortex to hearing in multiple contexts. Here we determined the role of ferret primary auditory cortex in both spatial and nonspatial hearing by reversibly inactivating the middle ectosylvian gyrus during behavior using cooling (n = 2 females) or optogenetics (n = 1 female). Optogenetic experiments used the mDLx promoter to express Channelrhodopsin-2 in GABAergic interneurons, and we confirmed both viral expression (n = 2 females) and light-driven suppression of spiking activity in auditory cortex, recorded using Neuropixels under anesthesia (n = 465 units from 2 additional untrained female ferrets). Cortical inactivation via cooling or optogenetics impaired vowel discrimination in colocated noise. Ferrets implanted with cooling loops were tested in additional conditions that revealed no deficit when identifying vowels in clean conditions, or when the temporally coincident vowel and noise were spatially separated by 180 degrees. These animals did, however, show impaired sound localization when inactivating the same auditory cortical region implicated in vowel discrimination in noise. Our results demonstrate that, as a brain region showing mixed selectivity for spatial and nonspatial features of sound, primary auditory cortex contributes to multiple forms of hearing."	"Town, S.M., Poole, K.C., Wood, K.C., Bizley, J.K., 2023. Reversible Inactivation of Ferret Auditory Cortex Impairs Spatial and Nonspatial Hearing. J. Neurosci. 43, 749–763. https://doi.org/10.1523/JNEUROSCI.1426-22.2022"	ferret-opto	https://doi.org/10.1523/JNEUROSCI.1426-22.2022
07/08/2020	Seasonal weight changes in laboratory ferrets	PLOS ONE	"Ferrets (Mustela putorius furo) are a valuable animal model used in biomedical research. Like many animals, ferrets undergo significant variation in body weight seasonally, affected by photoperiod, and these variations complicate the use weight as an indicator of health status. To overcome this requires a better understanding of these seasonal weight changes. We provide a normative weight data set for the female ferret accounting for seasonal changes, and also investigate the effect of fluid regulation on weight change. Female ferrets (n = 39) underwent behavioural testing from May 2017 to August 2019 and were weighed daily, while housed in an animal care facility with controlled light exposure. In the winter (October to March), animals experienced 10 hours of light and 14 hours of dark, while in summer (March to October), this contingency was reversed. Individual animals varied in their body weight from approximately 700 to 1200 g. However, weights fluctuated with light cycle, with animals losing weight in summer, and gaining weight in winter such that they fluctuated between approximately 80% and 120% of their long-term average. Ferrets were weighed as part of their health assessment while experiencing water regulation for behavioural training. Water regulation superimposed additional weight changes on these seasonal fluctuations, with weight loss during the 5-day water regulation period being greater in summer than winter. Analysing the data with a Generalised Linear Model confirmed that the percentage decrease in weight per week was relatively constant throughout the summer months, while the percentage increase in body weight per week in winter decreased through the season. Finally, we noted that the timing of oestrus was reliably triggered by the increase in day length in spring. These data establish a normative benchmark for seasonal weight variation in female ferrets that can be incorporated into the health assessment of an animal’s condition."	"Jones, E.J., Poole, K.C., Sollini, J., Town, S.M., Bizley, J.K., 2020. Seasonal weight changes in laboratory ferrets. PLOS ONE 15, e0232733. https://doi.org/10.1371/journal.pone.0232733"	ferret-weights	https://doi.org/10.1371/journal.pone.0232733
11/09/2023	Adaptation to Altered Interaural Time Differences in a Virtual Reality Environment	Forum Acousticum 2023	"Interaural time differences (ITDs) are important cues for determining the azimuth location of a sound source in the horizontal plane. In a virtual reality (VR) environment, they need to be accurately reproduced for the listener to have a realistic sense of sound localisation. ITDs are usually included within the head related transfer function (HRTF) used for audio rendering, and can be individualised to match the user’s head size. In recent years, studies have shown that it is possible to train subjects to adapt to non-personalized HRTFs. The analysis of such improvements has though focused mainly on adaptation to monoaural spectral cues rather than to interaural differences. In this work listeners are placed in a VR environment and are asked to localise a noise burst source in the horizontal plane. Using a generic HRTF with its ITD modified to match the head size of each participant, test and training phases are alternated, with the latter providing continuous auditory feedback. The experiment is repeated with ITDs simulating larger (150%) and smaller (50%) head sizes. Comparing localisation accuracy before and after training, it is observed that while training seems to improve results, this varies according to the simulated head size and session order."	"Guiraud, P., Sum, K., Pontoppidan, N., Poole, K., Picinali, L., 2023. ADAPTATION TO ALTERED INTERAURAL TIME DIFFERENCES IN A VIRTUAL REALITY ENVIRONMENT"	various-ITDs	https://www.researchgate.net/profile/Lorenzo-Picinali/publication/374117370_ADAPTATION_TO_ALTERED_INTERAURAL_TIME_DIFFERENCES_IN_A_VIRTUAL_REALITY_ENVIRONMENT/links/650e8ac661f18040c218ca4b/ADAPTATION-TO-ALTERED-INTERAURAL-TIME-DIFFERENCES-IN-A-VIRTUAL-REALITY-ENVIRONMENT.pdf
